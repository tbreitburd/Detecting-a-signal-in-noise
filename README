# S1 Principles of Data Science Coursework  

## Description  
This repositery contains the code and written report for the S1 PDS coursework. The aim was to demonstrate the applications of statistical methods, including coding them.

## Contents  
Inside this ```tmb76/``` directory, there are 3 sub-directories to explore. One is the code directory (```src/```), which contains all the code used to generate the results and plots. The second is the plots directory (```Plots/```), which contains all the plots generated by the code. An important note is that the plots directry will be created by the code if it does not exist yet. So if there is no plots directory in the repository yet, running all the code should lead to creating and filling one. The last one is the report directory, which contains the LaTeX file for the report, as well as the pdf version of it.  
More importantly, there are an ```environment.yml``` file and a ```Dockerfile```, which uses it, and one is advised to use.

## How to run the code
For permissions reasons, the ```Dockerfile``` is not set up to pull the repository directly as it builds the image. Therefore, one must first pull this repository to their local machine and then are free to build the Docker image from the ```Dockerfile```, using the following command:

```bash
$ docker build -t pdscw .
$ docker run -ti --name=pdscw_container pdscw
```

The given image name is not a requirement, it can be set to any valid name. The 2nd line does not use ```--rm```, which means the container will not be removed once exited. This is so that once the code is run on the container the plots directory can be copied back to the local machine using this command after using ```exit``` to exit the container:

```bash
$ docker cp pdscw_container:/S1_Coursework/plots ./plots
```

This means the container can and should be removed after the plots have been copied:

```bash
$ docker rm pdscw_container
```

All code can be run from the command line (in the container) as follows:

```bash
$ python src/solve_part_*.py
```

where * can be letters c through to g.
Additionally, there is a ```ndof_for_part_f_g.py``` file which covers determining the appropriate number of degrees of freedom to be used in parts (f) and (g) (cf. part (f) and (g)'s code). This is also in the ```src/``` directory, and can therefore be run in a similar fashion:

```bash
$ python src/ndof_for_part_f_g.py
```

Relevant outputs will be printed by the code, and any plots generated will be saved to a ```Plots/``` directory inside ```tmb76/```, that will get created if it doesn't exist yet.

This can all be done within a Docker container, by building an image from the \texttt{Dockerfile}, and running a container from it. 

From there, all files can be run in the same manner as above.

## Note on time

The codes for part (c) to part (e) should each take less than a minute to run. For part (f), the code should take less than 5 minutes, with part (g) taking a little longer at The ```ndof_for_part_f_g.py``` is one of the more time consuming files to run, and could take around 10-15 minutes to run. This is based on running all of these on a MacBook Air M2 (2022, Ventura 13.2.1), with 8 GB of Memory.

## Use of generative AI

Copilot's autocompletion feature was used in coding the project, when writing docstrings for the functions, and when covering repetitive parts of the code, like part (f) and (g)'s hypothesis testing.
ChatGPT was used to help in debugging the code, by providing the tracebacks when an error was difficult to understand.